{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "import string\n",
    "from collections import Counter\n",
    "from nltk import word_tokenize, FreqDist, bigrams\n",
    "from nltk.corpus import stopwords\n",
    "import category_encoders as ce\n",
    "from sklearn.preprocessing import MinMaxScaler, PolynomialFeatures\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_selection import SelectKBest, chi2, RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline\n",
    "from skopt import BayesSearchCV\n",
    "\n",
    "# import nltk\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)\n",
    "\n",
    "# from fuzzywuzzy import process\n",
    "# from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_raw = pd.read_csv('train.csv')\n",
    "df_test_raw = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train_raw.copy()\n",
    "df_test = df_test_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7608</th>\n",
       "      <td>10869</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7609</th>\n",
       "      <td>10870</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7610</th>\n",
       "      <td>10871</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7611</th>\n",
       "      <td>10872</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Police investigating after an e-bike collided ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7612</th>\n",
       "      <td>10873</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7613 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id keyword location  \\\n",
       "0         1     NaN      NaN   \n",
       "1         4     NaN      NaN   \n",
       "2         5     NaN      NaN   \n",
       "3         6     NaN      NaN   \n",
       "4         7     NaN      NaN   \n",
       "...     ...     ...      ...   \n",
       "7608  10869     NaN      NaN   \n",
       "7609  10870     NaN      NaN   \n",
       "7610  10871     NaN      NaN   \n",
       "7611  10872     NaN      NaN   \n",
       "7612  10873     NaN      NaN   \n",
       "\n",
       "                                                   text  target  \n",
       "0     Our Deeds are the Reason of this #earthquake M...       1  \n",
       "1                Forest fire near La Ronge Sask. Canada       1  \n",
       "2     All residents asked to 'shelter in place' are ...       1  \n",
       "3     13,000 people receive #wildfires evacuation or...       1  \n",
       "4     Just got sent this photo from Ruby #Alaska as ...       1  \n",
       "...                                                 ...     ...  \n",
       "7608  Two giant cranes holding a bridge collapse int...       1  \n",
       "7609  @aria_ahrary @TheTawniest The out of control w...       1  \n",
       "7610  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...       1  \n",
       "7611  Police investigating after an e-bike collided ...       1  \n",
       "7612  The Latest: More Homes Razed by Northern Calif...       1  \n",
       "\n",
       "[7613 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>2533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "id           0\n",
       "keyword     61\n",
       "location  2533\n",
       "text         0\n",
       "target       0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_train.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.duplicated().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Disasters:\t3271 (43.0%)\n",
      "Not disasters:\t4342 (57.0%)\n"
     ]
    }
   ],
   "source": [
    "print(f'Disasters:\\t{df_train[df_train.target==1].shape[0]} ({round(df_train[df_train.target==1].shape[0]/df_train.shape[0]*100,1)}%)')\n",
    "print(f'Not disasters:\\t{df_train[df_train.target==0].shape[0]} ({round(df_train[df_train.target==0].shape[0]/df_train.shape[0]*100,1)}%)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "221"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['keyword'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>derailment</th>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>outbreak</th>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wreckage</th>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debris</th>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oil%20spill</th>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>typhoon</th>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rescuers</th>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide%20bomb</th>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suicide%20bombing</th>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evacuated</th>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          count\n",
       "keyword           target       \n",
       "derailment        1          39\n",
       "outbreak          1          39\n",
       "wreckage          1          39\n",
       "debris            1          37\n",
       "oil%20spill       1          37\n",
       "typhoon           1          37\n",
       "rescuers          1          32\n",
       "suicide%20bomb    1          32\n",
       "suicide%20bombing 1          32\n",
       "evacuated         1          32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_train[df_train['target']==1][['keyword','target']].groupby('keyword').value_counts().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>keyword</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>body%20bags</th>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>armageddon</th>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harm</th>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deluge</th>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ruin</th>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wrecked</th>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>explode</th>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fear</th>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>twister</th>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>siren</th>\n",
       "      <th>0</th>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    count\n",
       "keyword     target       \n",
       "body%20bags 0          40\n",
       "armageddon  0          37\n",
       "harm        0          37\n",
       "deluge      0          36\n",
       "ruin        0          36\n",
       "wrecked     0          36\n",
       "explode     0          35\n",
       "fear        0          35\n",
       "twister     0          35\n",
       "siren       0          35"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_train[df_train['target']==0][['keyword','target']].groupby('keyword').value_counts().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>target_mean</th>\n",
       "      <th>keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>debris</td>\n",
       "      <td>1.000</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>derailment</td>\n",
       "      <td>1.000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>219</th>\n",
       "      <td>wreckage</td>\n",
       "      <td>1.000</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>outbreak</td>\n",
       "      <td>0.975</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>oil%20spill</td>\n",
       "      <td>0.974</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>typhoon</td>\n",
       "      <td>0.974</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>suicide%20bombing</td>\n",
       "      <td>0.970</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>suicide%20bomber</td>\n",
       "      <td>0.968</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               keyword  target_mean  keyword_count\n",
       "62              debris        1.000             37\n",
       "70          derailment        1.000             39\n",
       "219           wreckage        1.000             39\n",
       "153           outbreak        0.975             40\n",
       "152        oil%20spill        0.974             38\n",
       "205            typhoon        0.974             38\n",
       "187  suicide%20bombing        0.970             33\n",
       "186   suicide%20bomber        0.968             31"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('keyword', as_index=False).agg(target_mean=('target','mean'), keyword_count=('target','size')).query('target_mean > 0.95').sort_values('target_mean', ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keyword</th>\n",
       "      <th>target_mean</th>\n",
       "      <th>keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aftershock</td>\n",
       "      <td>0.000</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>body%20bags</td>\n",
       "      <td>0.024</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>ruin</td>\n",
       "      <td>0.027</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>blazing</td>\n",
       "      <td>0.029</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>body%20bag</td>\n",
       "      <td>0.030</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>electrocute</td>\n",
       "      <td>0.031</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         keyword  target_mean  keyword_count\n",
       "2     aftershock        0.000             34\n",
       "29   body%20bags        0.024             41\n",
       "170         ruin        0.027             37\n",
       "19       blazing        0.029             34\n",
       "27    body%20bag        0.030             33\n",
       "88   electrocute        0.031             32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('keyword', as_index=False).agg(target_mean=('target','mean'), keyword_count=('target','size')).query('target_mean <0.05').sort_values('target_mean', ascending=True).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3341"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['location'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glasgow</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Melbourne, Australia</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>News</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ã¥_</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ã¥_: ?? ÃŒÃ‘ ? : ?</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ã¥_Ã¥_Los Mina CityÂ‰Ã£Â¢</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ã¥Â¡Ã¥Â¡Midwest Â‰Ã›Â¢Â‰Ã›Â¢</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ã¥ÃŠ(?Â‰Ã›Â¢`?Â‰Ã›Â¢Ã¥Â«)??</th>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ã¥Ã¸\\_(?)_/Ã¥Ã¸</th>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3655 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                               count\n",
       "location               target       \n",
       "                       1           1\n",
       "  Glasgow              0           1\n",
       "  Melbourne, Australia 0           1\n",
       "  News                 1           1\n",
       "  Ã¥_                   0           1\n",
       "...                              ...\n",
       "Ã¥_: ?? ÃŒÃ‘ ? : ?        0           1\n",
       "Ã¥_Ã¥_Los Mina CityÂ‰Ã£Â¢   0           1\n",
       "Ã¥Â¡Ã¥Â¡Midwest Â‰Ã›Â¢Â‰Ã›Â¢     0           1\n",
       "Ã¥ÃŠ(?Â‰Ã›Â¢`?Â‰Ã›Â¢Ã¥Â«)??      0           1\n",
       "Ã¥Ã¸\\_(?)_/Ã¥Ã¸            1           1\n",
       "\n",
       "[3655 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_train[['location','target']].groupby('location').value_counts())\n",
    "# grouped_counts = df_train[['location','target']].groupby('location').value_counts()\n",
    "# grouped_counts[grouped_counts > 10].index.get_level_values('location').unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <th>1</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Nigeria</th>\n",
       "      <th>1</th>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>India</th>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mumbai</th>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London</th>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Washington, DC</th>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       count\n",
       "location       target       \n",
       "USA            1          67\n",
       "United States  1          27\n",
       "Nigeria        1          22\n",
       "India          1          20\n",
       "Mumbai         1          19\n",
       "UK             1          16\n",
       "London         1          16\n",
       "New York       1          16\n",
       "Washington, DC 1          15\n",
       "Canada         1          13"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_train[df_train['target']==1][['location','target']].groupby('location').value_counts().sort_values(ascending=False).head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>New York</th>\n",
       "      <th>0</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>London</th>\n",
       "      <th>0</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>United States</th>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Los Angeles, CA</th>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Canada</th>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kenya</th>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Everywhere</th>\n",
       "      <th>0</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UK</th>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Florida</th>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        count\n",
       "location        target       \n",
       "New York        0          55\n",
       "USA             0          37\n",
       "London          0          29\n",
       "United States   0          23\n",
       "Los Angeles, CA 0          18\n",
       "Canada          0          16\n",
       "Kenya           0          15\n",
       "Everywhere      0          12\n",
       "UK              0          11\n",
       "Florida         0          11"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(df_train[df_train['target']==0][['location','target']].groupby('location').value_counts().sort_values(ascending=False).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>target_mean</th>\n",
       "      <th>keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3340</th>\n",
       "      <td>Ã¥Ã¸\\_(?)_/Ã¥Ã¸</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>News</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>616 Â‰Ã›Â¢ Kentwood , MI</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>? ??????? ? ( ?? Ã¥Â¡ ? ? ? Ã¥Â¡)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>#partsunknown</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>#keepthefaith J&amp;J</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>#iminchina</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>#goingdownthetoilet Illinois</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>#WashingtonState #Seattle</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1199 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            location  target_mean  keyword_count\n",
       "3340                     Ã¥Ã¸\\_(?)_/Ã¥Ã¸          1.0              1\n",
       "0                                             1.0              1\n",
       "3                               News          1.0              1\n",
       "6             616 Â‰Ã›Â¢ Kentwood , MI           1.0              1\n",
       "7      ? ??????? ? ( ?? Ã¥Â¡ ? ? ? Ã¥Â¡)          1.0              1\n",
       "...                              ...          ...            ...\n",
       "65                     #partsunknown          1.0              1\n",
       "63                 #keepthefaith J&J          1.0              1\n",
       "62                        #iminchina          1.0              1\n",
       "61      #goingdownthetoilet Illinois          1.0              1\n",
       "57         #WashingtonState #Seattle          1.0              1\n",
       "\n",
       "[1199 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('location', as_index=False).agg(target_mean=('target','mean'), keyword_count=('target','size')).query('target_mean > 0.95').sort_values('target_mean', ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>target_mean</th>\n",
       "      <th>keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3339</th>\n",
       "      <td>Ã¥ÃŠ(?Â‰Ã›Â¢`?Â‰Ã›Â¢Ã¥Â«)??</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Glasgow</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ã¥_</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>Â‰Ã›Â¢OlderCandyBloomÂ‰Ã›Â¢</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Eugene, Oregon</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Blood Indian Reserve</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BC, US, Asia or Europe.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Alex/Mika/Leo|18|he/she/they</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>?currently writing a book?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1828 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           location  target_mean  keyword_count\n",
       "3339              Ã¥ÃŠ(?Â‰Ã›Â¢`?Â‰Ã›Â¢Ã¥Â«)??          0.0              1\n",
       "1                          Glasgow           0.0              1\n",
       "2              Melbourne, Australia          0.0              1\n",
       "4                               Ã¥_           0.0              1\n",
       "3315          Â‰Ã›Â¢OlderCandyBloomÂ‰Ã›Â¢          0.0              1\n",
       "...                             ...          ...            ...\n",
       "15                   Eugene, Oregon          0.0              1\n",
       "13             Blood Indian Reserve          0.0              1\n",
       "11          BC, US, Asia or Europe.          0.0              1\n",
       "10     Alex/Mika/Leo|18|he/she/they          0.0              1\n",
       "8        ?currently writing a book?          0.0              1\n",
       "\n",
       "[1828 rows x 3 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('location', as_index=False).agg(target_mean=('target','mean'), keyword_count=('target','size')).query('target_mean < 0.05').sort_values('target_mean', ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>0.863636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>India</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>Paterson, New Jersey</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>Pedophile hunting ground</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1426</th>\n",
       "      <td>Lagos, Nigeria</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>Melbourne, Australia</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2124</th>\n",
       "      <td>Puerto Rico</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2538</th>\n",
       "      <td>The Netherlands</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2866</th>\n",
       "      <td>WorldWide</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1860</th>\n",
       "      <td>Nigeria</td>\n",
       "      <td>0.785714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1788</th>\n",
       "      <td>Nashville, TN</td>\n",
       "      <td>0.777778</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      location    target\n",
       "1719                    Mumbai  0.863636\n",
       "1262                     India  0.833333\n",
       "1934         Oklahoma City, OK  0.833333\n",
       "2028     Paterson, New Jersey   0.833333\n",
       "2032  Pedophile hunting ground  0.833333\n",
       "1426            Lagos, Nigeria  0.800000\n",
       "1636      Melbourne, Australia  0.800000\n",
       "2124               Puerto Rico  0.800000\n",
       "2538           The Netherlands  0.800000\n",
       "2866                 WorldWide  0.800000\n",
       "1860                   Nigeria  0.785714\n",
       "1788             Nashville, TN  0.777778"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('location', as_index=False)['target'].mean().query('target > 0.75 & target < 1.0').sort_values('target', ascending=False)\n",
    "# ['location'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1511</th>\n",
       "      <td>London, England</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3222</th>\n",
       "      <td>ss</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>578</th>\n",
       "      <td>California, United States</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Road to the Billionaires Club</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1759</th>\n",
       "      <td>NYC</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>Brooklyn, NY</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>Boston, MA</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2255</th>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>934</th>\n",
       "      <td>Everywhere</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1840</th>\n",
       "      <td>New York, USA</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>New Jersey</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2699</th>\n",
       "      <td>Vancouver, BC</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>Florida</td>\n",
       "      <td>0.214286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>Manchester</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1826</th>\n",
       "      <td>New York</td>\n",
       "      <td>0.225352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            location    target\n",
       "1511                 London, England  0.100000\n",
       "3222                              ss  0.100000\n",
       "578        California, United States  0.166667\n",
       "27     Road to the Billionaires Club  0.166667\n",
       "1759                             NYC  0.166667\n",
       "525                     Brooklyn, NY  0.166667\n",
       "495                           Brasil  0.200000\n",
       "484                       Boston, MA  0.200000\n",
       "2255                    San Jose, CA  0.200000\n",
       "934                       Everywhere  0.200000\n",
       "1840                   New York, USA  0.200000\n",
       "1814                      New Jersey  0.200000\n",
       "2699                   Vancouver, BC  0.200000\n",
       "959                          Florida  0.214286\n",
       "1599                      Manchester  0.222222\n",
       "1826                        New York  0.225352"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('location', as_index=False)['target'].mean().query('target > 0.0 & target < 0.25').sort_values('target', ascending=True)\n",
    "# ['location'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>target_mean</th>\n",
       "      <th>keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1719</th>\n",
       "      <td>Mumbai</td>\n",
       "      <td>0.864</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>India</td>\n",
       "      <td>0.833</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2028</th>\n",
       "      <td>Paterson, New Jersey</td>\n",
       "      <td>0.833</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1934</th>\n",
       "      <td>Oklahoma City, OK</td>\n",
       "      <td>0.833</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2032</th>\n",
       "      <td>Pedophile hunting ground</td>\n",
       "      <td>0.833</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      location  target_mean  keyword_count\n",
       "1719                    Mumbai        0.864             22\n",
       "1262                     India        0.833             24\n",
       "2028     Paterson, New Jersey         0.833              6\n",
       "1934         Oklahoma City, OK        0.833              6\n",
       "2032  Pedophile hunting ground        0.833              6"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('location', as_index=False).agg(target_mean=('target','mean'), keyword_count=('target','size')).query('keyword_count >= 5').sort_values('keyword_count', ascending=False).sort_values('target_mean', ascending=False).head(5).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>location</th>\n",
       "      <th>target_mean</th>\n",
       "      <th>keyword_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1708</th>\n",
       "      <td>Morioh, Japan</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2039</th>\n",
       "      <td>Pennsylvania, USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2851</th>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2503</th>\n",
       "      <td>Texas, USA</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               location  target_mean  keyword_count\n",
       "1708      Morioh, Japan          0.0              6\n",
       "2039  Pennsylvania, USA          0.0              7\n",
       "114                 304          0.0              9\n",
       "2851          Wisconsin          0.0              5\n",
       "2503         Texas, USA          0.0              5"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.groupby('location', as_index=False).agg(target_mean=('target','mean'), keyword_count=('target','size')).query('keyword_count >= 5').sort_values('keyword_count', ascending=False).sort_values('target_mean', ascending=True).head(5).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train['cleaned_location'] = df_train['location']\n",
    "# df_train['cleaned_location'] = df_train['cleaned_location'].fillna('unknown')\n",
    "\n",
    "# standard_locations = ['Canada','Florida','India','Kenya','London','Los Angeles, CA','Mumbai','New York','Nigeria','UK','USA','United States','Washington, DC','Oklahoma City, OK','Paterson, New Jersey','Lagos, Nigeria','Melbourne, Australia','Puerto Rico','The Netherlands','Nashville, TN','London, England','California, United States','NYC','Brooklyn, NY','Brasil','Boston, MA','San Jose, CA','New York, USA','New Jersey','Vancouver, BC','Manchester']\n",
    "\n",
    "# def generate_location_mapping(train_locations, standard_locations):\n",
    "#     location_mapping = {}\n",
    "#     for loc in train_locations:\n",
    "#         match, score = process.extractOne(loc, standard_locations)\n",
    "#         location_mapping[loc] = match if score > 90 else loc\n",
    "#     return location_mapping\n",
    "\n",
    "# unique_train_locations = df_train['cleaned_location'].unique()\n",
    "# location_mapping = generate_location_mapping(unique_train_locations, standard_locations)\n",
    "\n",
    "# def clean_locations(location, mapping):\n",
    "#     return mapping.get(location, location)\n",
    "\n",
    "# df_train['cleaned_location'] = df_train['cleaned_location'].apply(lambda x: clean_locations(x, location_mapping))\n",
    "\n",
    "# df_train[(df_train['cleaned_location'] != df_train['location']) & (df_train['cleaned_location'] != 'unknown')][['location','cleaned_location']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltkstopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_newlines(text): return re.sub(r'\\n', ' ', text).strip()\n",
    "\n",
    "def fix_html_entities(text): return html.unescape(text)\n",
    "\n",
    "def extract_elements(text, element_type):\n",
    "    patterns = {  'hashtags': r'#[A-Za-z0-9-_]+',\n",
    "                  'handles': r'@[A-Za-z0-9-_]+',\n",
    "                  'urls': r'https?://t.co/[A-Za-z0-9]{10}'  }\n",
    "    pattern = re.compile(patterns[element_type])\n",
    "    elements = pattern.findall(text)\n",
    "    n = len(elements)\n",
    "    elements_str = ' '.join(elements)\n",
    "    new_text = pattern.sub('', text)\n",
    "    return new_text.strip(), elements_str, n\n",
    "\n",
    "# def extract_hashtags(text):\n",
    "#     pattern = re.compile(r'#[A-Za-z0-9-_]+')\n",
    "#     hashtags = pattern.findall(text)\n",
    "#     n = len(hashtags)\n",
    "#     hashtags_str = ' '.join(hashtags)\n",
    "#     new_text = pattern.sub('', text)\n",
    "#     return new_text.strip(), hashtags_str, n\n",
    "\n",
    "# def extract_handles(text):\n",
    "#     pattern = re.compile(r'@[A-Za-z0-9-_]+')\n",
    "#     handles = pattern.findall(text)\n",
    "#     n = len(handles)\n",
    "#     handles_str = ' '.join(handles)\n",
    "#     new_text = pattern.sub('', text)\n",
    "#     return new_text.strip(), handles_str, n\n",
    "\n",
    "# def extract_urls(text):\n",
    "#     pattern = re.compile(r'https?://t.co/[A-Za-z0-9]{10}')\n",
    "#     urls = pattern.findall(text)\n",
    "#     n = len(urls)\n",
    "#     urls_str = ' '.join(urls)\n",
    "#     new_text = pattern.sub('', text)\n",
    "#     return new_text.strip(), urls_str, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['text_clean'] = df_train['text'].apply(lambda x: remove_newlines(x))\n",
    "df_train['text_clean'] = df_train['text_clean'].apply(lambda x: fix_html_entities(x))\n",
    "df_train[['text_clean', 'hashtags', 'n_hashtags']] = df_train['text_clean'].apply(lambda x: extract_elements(x,'hashtags')).apply(pd.Series)\n",
    "df_train[['text_clean', 'handles', 'n_handles']] = df_train['text_clean'].apply(lambda x: extract_elements(x,'handles')).apply(pd.Series)\n",
    "df_train[['text_clean', 'urls', 'n_urls']] = df_train['text_clean'].apply(lambda x: extract_elements(x,'urls')).apply(pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_clean</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>n_hashtags</th>\n",
       "      <th>handles</th>\n",
       "      <th>n_handles</th>\n",
       "      <th>urls</th>\n",
       "      <th>n_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/yN...</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_</td>\n",
       "      <td>#Dubstep #TrapMusic #DnB #EDM #Dance #Ices</td>\n",
       "      <td>6</td>\n",
       "      <td>@djicemoon</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/yNXnvVKCDA http://t.co/weQPesENku</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_</td>\n",
       "      <td>#Dubstep #TrapMusic #DnB #EDM #Dance #Ices</td>\n",
       "      <td>6</td>\n",
       "      <td>@djicemoon</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/vAM5POdGyw http://t.co/zEVakJaPcz</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/M4...</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_</td>\n",
       "      <td>#Dubstep #TrapMusic #DnB #EDM #Dance #Ices</td>\n",
       "      <td>6</td>\n",
       "      <td>@djicemoon</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/M4JDZMGJoW http://t.co/n0uhAsfkBv</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_</td>\n",
       "      <td>#Dubstep #TrapMusic #DnB #EDM #Dance #Ices</td>\n",
       "      <td>6</td>\n",
       "      <td>@djicemoon</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/vAM5POdGyw http://t.co/zEVakJaPcz</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/e1...</td>\n",
       "      <td>320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_</td>\n",
       "      <td>#Dubstep #TrapMusic #DnB #EDM #Dance #Ices</td>\n",
       "      <td>6</td>\n",
       "      <td>@djicemoon</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/e14EPzhotH http://t.co/22a9D5DO6q</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6993</th>\n",
       "      <td>This is my jam: Riser by Dierks Bentley @1061T...</td>\n",
       "      <td>This is my jam: Riser by Dierks Bentley  ?</td>\n",
       "      <td>#iHeartRadio #NowPlaying</td>\n",
       "      <td>2</td>\n",
       "      <td>@1061TheTwister</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/zQoScQD64h http://t.co/yLvVF139BB</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>#breaking #news Global precipitation measureme...</td>\n",
       "      <td>Global precipitation measurement satellite cap...</td>\n",
       "      <td>#breaking #news</td>\n",
       "      <td>2</td>\n",
       "      <td>@NASAHurricane</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/20DNcthr4D</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7279</th>\n",
       "      <td>Whirlwind Head Scissor on @alexhammerstone @kt...</td>\n",
       "      <td>Whirlwind Head Scissor on   ktfounder  Â‰Ã›_</td>\n",
       "      <td>#RemyMarcel #FroFroFro</td>\n",
       "      <td>2</td>\n",
       "      <td>@alexhammerstone @kttape</td>\n",
       "      <td>2</td>\n",
       "      <td>https://t.co/B19z8Vi3td</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7406</th>\n",
       "      <td>Twilight's Encore (Wounded Hearts Book 3) by J...</td>\n",
       "      <td>Twilight's Encore (Wounded Hearts Book 3) by J...</td>\n",
       "      <td>#KindleCountdown #Sale #MFRWauthor #MGTAB</td>\n",
       "      <td>4</td>\n",
       "      <td>@amazon</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/ZnpTdIcQxE</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7596</th>\n",
       "      <td>RT @LivingSafely: #NWS issues Severe #Thunders...</td>\n",
       "      <td>RT :  issues Severe  Warnings for parts of   ....</td>\n",
       "      <td>#NWS #Thunderstorm #AR #NC #OK</td>\n",
       "      <td>5</td>\n",
       "      <td>@LivingSafely</td>\n",
       "      <td>1</td>\n",
       "      <td>http://t.co/FWqfCKNCQW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>104 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  \\\n",
       "104   320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/yN...   \n",
       "106   320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...   \n",
       "114   320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/M4...   \n",
       "115   320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/vA...   \n",
       "116   320 [IR] ICEMOON [AFTERSHOCK] | http://t.co/e1...   \n",
       "...                                                 ...   \n",
       "6993  This is my jam: Riser by Dierks Bentley @1061T...   \n",
       "7022  #breaking #news Global precipitation measureme...   \n",
       "7279  Whirlwind Head Scissor on @alexhammerstone @kt...   \n",
       "7406  Twilight's Encore (Wounded Hearts Book 3) by J...   \n",
       "7596  RT @LivingSafely: #NWS issues Severe #Thunders...   \n",
       "\n",
       "                                             text_clean  \\\n",
       "104      320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_   \n",
       "106      320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_   \n",
       "114      320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_   \n",
       "115      320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_   \n",
       "116      320 [IR] ICEMOON [AFTERSHOCK] |  |  |      Â‰Ã›_   \n",
       "...                                                 ...   \n",
       "6993         This is my jam: Riser by Dierks Bentley  ?   \n",
       "7022  Global precipitation measurement satellite cap...   \n",
       "7279         Whirlwind Head Scissor on   ktfounder  Â‰Ã›_   \n",
       "7406  Twilight's Encore (Wounded Hearts Book 3) by J...   \n",
       "7596  RT :  issues Severe  Warnings for parts of   ....   \n",
       "\n",
       "                                        hashtags  n_hashtags  \\\n",
       "104   #Dubstep #TrapMusic #DnB #EDM #Dance #Ices           6   \n",
       "106   #Dubstep #TrapMusic #DnB #EDM #Dance #Ices           6   \n",
       "114   #Dubstep #TrapMusic #DnB #EDM #Dance #Ices           6   \n",
       "115   #Dubstep #TrapMusic #DnB #EDM #Dance #Ices           6   \n",
       "116   #Dubstep #TrapMusic #DnB #EDM #Dance #Ices           6   \n",
       "...                                          ...         ...   \n",
       "6993                    #iHeartRadio #NowPlaying           2   \n",
       "7022                             #breaking #news           2   \n",
       "7279                      #RemyMarcel #FroFroFro           2   \n",
       "7406   #KindleCountdown #Sale #MFRWauthor #MGTAB           4   \n",
       "7596              #NWS #Thunderstorm #AR #NC #OK           5   \n",
       "\n",
       "                       handles  n_handles  \\\n",
       "104                 @djicemoon          1   \n",
       "106                 @djicemoon          1   \n",
       "114                 @djicemoon          1   \n",
       "115                 @djicemoon          1   \n",
       "116                 @djicemoon          1   \n",
       "...                        ...        ...   \n",
       "6993           @1061TheTwister          1   \n",
       "7022            @NASAHurricane          1   \n",
       "7279  @alexhammerstone @kttape          2   \n",
       "7406                   @amazon          1   \n",
       "7596             @LivingSafely          1   \n",
       "\n",
       "                                               urls  n_urls  \n",
       "104   http://t.co/yNXnvVKCDA http://t.co/weQPesENku       2  \n",
       "106   http://t.co/vAM5POdGyw http://t.co/zEVakJaPcz       2  \n",
       "114   http://t.co/M4JDZMGJoW http://t.co/n0uhAsfkBv       2  \n",
       "115   http://t.co/vAM5POdGyw http://t.co/zEVakJaPcz       2  \n",
       "116   http://t.co/e14EPzhotH http://t.co/22a9D5DO6q       2  \n",
       "...                                             ...     ...  \n",
       "6993  http://t.co/zQoScQD64h http://t.co/yLvVF139BB       2  \n",
       "7022                         http://t.co/20DNcthr4D       1  \n",
       "7279                        https://t.co/B19z8Vi3td       1  \n",
       "7406                         http://t.co/ZnpTdIcQxE       1  \n",
       "7596                         http://t.co/FWqfCKNCQW       1  \n",
       "\n",
       "[104 rows x 8 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[(df_train['text_clean'] != df_train['text']) & (df_train['n_hashtags'] >= 2) & (df_train['n_handles'] >= 1) & (df_train['n_urls'] >= 1)][['text','text_clean','hashtags','n_hashtags','handles','n_handles','urls','n_urls']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for element in ['hashtags', 'handles', 'urls']:\n",
    "#     mlb = MultiLabelBinarizer()\n",
    "#     one_hot = pd.DataFrame(mlb.fit_transform(df_train[element]), columns=mlb.classes_, index=df_train.index)\n",
    "#     # df_train = pd.concat([df_train, one_hot], axis=1)\n",
    "#     display(one_hot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_count(text): return len(text)\n",
    "\n",
    "def word_count(text): return len(text.split())\n",
    "\n",
    "def unique_word_count(text): return len(set(text.split()))\n",
    "\n",
    "def avg_word_length(text): return round(sum(len(word) for word in text.split()) / len(text.split()),3)\n",
    "\n",
    "def punctuation_count(text): return len([n for n in text if n in string.punctuation])\n",
    "\n",
    "def stopwords_count(text): return len([n for n in text if n in nltkstopwords])\n",
    "\n",
    "def caps_count(text): return sum([1 for n in text if n.isupper()])\n",
    "\n",
    "def repeated_words(text):\n",
    "    word_counts = Counter(text.split())\n",
    "    return ' '.join([word for word, count in word_counts.items() if count > 1 and word.lower() not in nltkstopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['char_count'] = df_train['text_clean'].apply(lambda x: char_count(x))\n",
    "df_train['word_count'] = df_train['text_clean'].apply(lambda x: word_count(x))\n",
    "df_train['unique_word_count'] = df_train['text_clean'].apply(lambda x: unique_word_count(x))\n",
    "df_train['avg_word_length'] = df_train['text_clean'].apply(lambda x: avg_word_length(x))\n",
    "df_train['punctuation_count'] = df_train['text_clean'].apply(lambda x: punctuation_count(x))\n",
    "df_train['stopwords_count'] = df_train['text_clean'].apply(lambda x: stopwords_count(x))\n",
    "df_train['caps_count'] = df_train['text_clean'].apply(lambda x: caps_count(x))\n",
    "df_train['repeated_words'] = df_train['text_clean'].apply(lambda x: repeated_words(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poly features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_features(df, poly=None):\n",
    "    cols = ['n_handles','n_hashtags','n_urls','char_count','word_count','unique_word_count','avg_word_length','punctuation_count','stopwords_count','caps_count']\n",
    "    numerical_features = df[cols]\n",
    "    if poly is None:\n",
    "        poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "        poly.fit(numerical_features)\n",
    "    poly_features = poly.transform(numerical_features)\n",
    "    poly_feature_names = poly.get_feature_names_out(numerical_features.columns)\n",
    "    df_poly = pd.DataFrame(poly_features, columns=poly_feature_names, index=df.index)\n",
    "    return pd.concat([df, df_poly], axis=1), poly\n",
    "\n",
    "df_train, poly = poly_features(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "n_urls stopwords_count         0.254\n",
       "n_urls char_count              0.228\n",
       "n_urls avg_word_length         0.212\n",
       "n_urls unique_word_count       0.205\n",
       "n_urls word_count              0.204\n",
       "                               ...  \n",
       "n_handles unique_word_count   -0.082\n",
       "n_handles avg_word_length     -0.085\n",
       "n_handles punctuation_count   -0.086\n",
       "n_handles                     -0.103\n",
       "n_handles                     -0.103\n",
       "Name: target, Length: 75, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.select_dtypes(include=['number']).drop('id', axis=1).corr()['target'].drop('target').sort_values(ascending=False).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_clean_text = ' '.join(df_train['text_clean']).lower()\n",
    "disaster_clean_text = ' '.join(df_train[df_train['target']==1]['text_clean']).lower()\n",
    "notdisaster_clean_text = ' '.join(df_train[df_train['target']==0]['text_clean']).lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fire', 175),\n",
       " ('via', 121),\n",
       " ('disaster', 111),\n",
       " ('california', 107),\n",
       " ('police', 106),\n",
       " ('suicide', 104),\n",
       " ('people', 103),\n",
       " ('like', 93),\n",
       " ('killed', 92),\n",
       " ('storm', 85),\n",
       " ('crash', 83),\n",
       " ('news', 83),\n",
       " ('fires', 83),\n",
       " ('families', 81),\n",
       " ('train', 79),\n",
       " ('buildings', 75),\n",
       " ('bomb', 74),\n",
       " ('two', 72),\n",
       " ('emergency', 71),\n",
       " ('attack', 69)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('like', 253),\n",
       " ('new', 168),\n",
       " ('get', 162),\n",
       " ('one', 129),\n",
       " ('body', 110),\n",
       " ('would', 105),\n",
       " ('via', 97),\n",
       " ('video', 94),\n",
       " ('got', 92),\n",
       " ('people', 92),\n",
       " ('love', 86),\n",
       " ('know', 85),\n",
       " ('back', 83),\n",
       " ('time', 82),\n",
       " ('see', 82),\n",
       " ('full', 81),\n",
       " ('emergency', 79),\n",
       " ('day', 78),\n",
       " ('going', 75),\n",
       " ('ca', 74)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'new get one body would video got love know back time see full day going ca'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'fire disaster california police suicide killed storm crash news fires families train buildings bomb two attack'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_tokens = [w for w in word_tokenize(full_clean_text) if (w not in nltkstopwords) & (w.isalpha())]\n",
    "disaster_tokens = [w for w in word_tokenize(disaster_clean_text) if (w not in nltkstopwords) & (w.isalpha())]\n",
    "notdisaster_tokens = [w for w in word_tokenize(notdisaster_clean_text) if (w not in nltkstopwords) & (w.isalpha())]\n",
    "\n",
    "top_disaster_tokens = FreqDist(disaster_tokens).most_common(20)\n",
    "top_notdisaster_tokens = FreqDist(notdisaster_tokens).most_common(20)\n",
    "display(top_disaster_tokens)\n",
    "display(top_notdisaster_tokens)\n",
    "\n",
    "top_disaster_words = [w for w,f in top_notdisaster_tokens]\n",
    "top_nondisaster_words = [w for w,f in top_disaster_tokens]\n",
    "display(' '.join([w for w in top_disaster_words if w not in top_nondisaster_words]))\n",
    "display(' '.join([w for w in top_nondisaster_words if w not in top_disaster_words]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('suicide bomber', 59),\n",
       " ('northern california', 41),\n",
       " ('oil spill', 38),\n",
       " ('burning buildings', 35),\n",
       " ('suicide bombing', 32),\n",
       " ('california wildfire', 32),\n",
       " ('bomber detonated', 30),\n",
       " ('homes razed', 29),\n",
       " ('latest homes', 28),\n",
       " ('razed northern', 28),\n",
       " ('pkk suicide', 28),\n",
       " ('detonated bomb', 28),\n",
       " ('old pkk', 27),\n",
       " ('debris found', 26),\n",
       " ('mass murder', 26),\n",
       " ('families sue', 26),\n",
       " ('sue legionnaires', 26),\n",
       " ('legionnaires families', 26),\n",
       " ('families affected', 26),\n",
       " ('affected fatal', 26)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('cross body', 38),\n",
       " ('liked video', 34),\n",
       " ('gon na', 32),\n",
       " ('wan na', 30),\n",
       " ('body bag', 26),\n",
       " ('body bagging', 23),\n",
       " ('burning buildings', 23),\n",
       " ('full read', 22),\n",
       " ('looks like', 21),\n",
       " ('feel like', 20),\n",
       " ('content policy', 20),\n",
       " ('body bags', 19),\n",
       " ('loud bang', 19),\n",
       " ('reddit quarantine', 19),\n",
       " ('quarantine offensive', 19),\n",
       " ('offensive content', 18),\n",
       " ('pick fan', 17),\n",
       " ('fan army', 17),\n",
       " ('fall cliff', 16),\n",
       " ('first responders', 16)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'suicide bomber | northern california | oil spill | suicide bombing | california wildfire | bomber detonated | homes razed | latest homes | razed northern | pkk suicide | detonated bomb | old pkk | debris found | mass murder | families sue | sue legionnaires | legionnaires families | families affected | affected fatal'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'cross body | liked video | gon na | wan na | body bag | body bagging | full read | looks like | feel like | content policy | body bags | loud bang | reddit quarantine | quarantine offensive | offensive content | pick fan | fan army | fall cliff | first responders'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_bigrams = [' '.join(b) for b in list(bigrams(all_tokens))]\n",
    "disaster_bigrams = [' '.join(b) for b in list(bigrams(disaster_tokens))]\n",
    "nondisaster_bigrams = [' '.join(b) for b in list(bigrams(notdisaster_tokens))]\n",
    "\n",
    "top_disaster_bigrams = FreqDist(disaster_bigrams).most_common(20)\n",
    "top_nondisaster_bigrams = FreqDist(nondisaster_bigrams).most_common(20)\n",
    "display(top_disaster_bigrams)\n",
    "display(top_nondisaster_bigrams)\n",
    "\n",
    "top_disaster_bigrams = [w for w,f in top_disaster_bigrams]\n",
    "top_nondisaster_bigrams = [w for w,f in top_nondisaster_bigrams]\n",
    "display(' | '.join([w for w in top_disaster_bigrams if w not in top_nondisaster_bigrams]))\n",
    "display(' | '.join([w for w in top_nondisaster_bigrams if w not in top_disaster_bigrams]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URLs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urls</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>1100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://t.co/KSAwlYuX02</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://t.co/LvlH3W3aWO http://t.co/vIwXY1XDYK</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>https://t.co/rqWuoy1fm4</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://t.co/V3aZWOAmzK</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://t.co/cybKsXHF7d</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://t.co/cEdCUgEuWs</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://t.co/po19h8YCND</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://t.co/EYSVvzA7Qm</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>http://t.co/zDtoyd8EbJ</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               target\n",
       "urls                                                 \n",
       "                                                 1100\n",
       "http://t.co/KSAwlYuX02                              6\n",
       "http://t.co/LvlH3W3aWO http://t.co/vIwXY1XDYK       4\n",
       "https://t.co/rqWuoy1fm4                             3\n",
       "http://t.co/V3aZWOAmzK                              3\n",
       "http://t.co/cybKsXHF7d                              3\n",
       "http://t.co/cEdCUgEuWs                              3\n",
       "http://t.co/po19h8YCND                              2\n",
       "http://t.co/EYSVvzA7Qm                              2\n",
       "http://t.co/zDtoyd8EbJ                              2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[['target','urls']].groupby('urls').sum().sort_values('target',ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Category Encoding: category_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['keyword', 'location']\n",
    "# features = ['keyword', 'cleaned_location']\n",
    "encoder = ce.TargetEncoder(cols=features)\n",
    "encoder.fit(df_train[features],df_train['target'])\n",
    "\n",
    "df_train = df_train.join(encoder.transform(df_train[features]).add_suffix('_target'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_urls = CountVectorizer(min_df=5, analyzer='word', token_pattern=r'https?://t.co/[A-Za-z0-9]{10}')\n",
    "urls_vec = vec_urls.fit_transform(df_train['urls'])\n",
    "X_train_urls = pd.DataFrame(urls_vec.toarray(), columns=vec_urls.get_feature_names_out())\n",
    "\n",
    "vec_handles = CountVectorizer(min_df=5)\n",
    "handles_vec = vec_handles.fit_transform(df_train['handles'])\n",
    "X_train_handles = pd.DataFrame(handles_vec.toarray(), columns=vec_handles.get_feature_names_out())\n",
    "\n",
    "vec_hashtags = CountVectorizer(min_df=5)\n",
    "hashtags_vec = vec_hashtags.fit_transform(df_train['hashtags'])\n",
    "X_train_hashtags = pd.DataFrame(hashtags_vec.toarray(), columns=vec_hashtags.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "http://t.co/vvplfqv58p    1.000000\n",
       "http://t.co/ksawlyux02    1.000000\n",
       "http://t.co/cybksxhf7d    0.600000\n",
       "http://t.co/encmhz6y34    0.166667\n",
       "http://t.co/q2eblokeve    0.166667\n",
       "http://t.co/qew4c5m1xd    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_urls.transpose().dot(df_train['target']) / X_train_urls.sum(axis=0)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ap               1.000000\n",
       "usagov           1.000000\n",
       "foxnews          0.888889\n",
       "potus            0.666667\n",
       "viralspell       0.600000\n",
       "usatoday         0.444444\n",
       "change           0.444444\n",
       "youngheroesid    0.400000\n",
       "youtube          0.216867\n",
       "towel            0.166667\n",
       "stretcher        0.166667\n",
       "emmerdale        0.125000\n",
       "mikeparractor    0.000000\n",
       "arianagrande     0.000000\n",
       "justinbieber     0.000000\n",
       "invalid          0.000000\n",
       "djicemoon        0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_handles.transpose().dot(df_train['target']) / X_train_handles.sum(axis=0)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abstorm       1.0\n",
       "africa        1.0\n",
       "antioch       1.0\n",
       "hailstorm     1.0\n",
       "india         1.0\n",
       "             ... \n",
       "military      0.0\n",
       "technology    0.0\n",
       "summerfate    0.0\n",
       "soundcloud    0.0\n",
       "trapmusic     0.0\n",
       "Length: 106, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(X_train_hashtags.transpose().dot(df_train['target']) / X_train_hashtags.sum(axis=0)).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction: TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_text = TfidfVectorizer(min_df=10, ngram_range=(1,10), stop_words='english') \n",
    "text_vec = vec_text.fit_transform(df_train['text_clean'])\n",
    "X_train_text = pd.DataFrame(text_vec.toarray(), columns=vec_text.get_feature_names_out())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.join(X_train_urls, rsuffix='_urls')\n",
    "df_train = df_train.join(X_train_handles, rsuffix='_handles')\n",
    "df_train = df_train.join(X_train_hashtags, rsuffix='_hashtags')\n",
    "df_train = df_train.join(X_train_text, rsuffix='_text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=42, solver='liblinear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prep test data, X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test['cleaned_location'] = df_test['location']\n",
    "# df_test['cleaned_location'] = df_test['cleaned_location'].fillna('unknown')\n",
    "# df_test['cleaned_location'] = df_test['cleaned_location'].apply(lambda x: clean_locations(x, location_mapping))\n",
    "\n",
    "df_test['text_clean'] = df_test['text'].apply(lambda x: remove_newlines(x))\n",
    "df_test['text_clean'] = df_test['text_clean'].apply(lambda x: fix_html_entities(x))\n",
    "df_test[['text_clean', 'hashtags', 'n_hashtags']] = df_test['text_clean'].apply(lambda x: extract_elements(x,'hashtags')).apply(pd.Series)\n",
    "df_test[['text_clean', 'handles', 'n_handles']] = df_test['text_clean'].apply(lambda x: extract_elements(x,'handles')).apply(pd.Series)\n",
    "df_test[['text_clean', 'urls', 'n_urls']] = df_test['text_clean'].apply(lambda x: extract_elements(x,'urls')).apply(pd.Series)\n",
    "df_test['char_count'] = df_test['text_clean'].apply(lambda x: char_count(x))\n",
    "df_test['word_count'] = df_test['text_clean'].apply(lambda x: word_count(x))\n",
    "df_test['unique_word_count'] = df_test['text_clean'].apply(lambda x: unique_word_count(x))\n",
    "df_test['avg_word_length'] = df_test['text_clean'].apply(lambda x: avg_word_length(x))\n",
    "df_test['punctuation_count'] = df_test['text_clean'].apply(lambda x: punctuation_count(x))\n",
    "df_test['stopwords_count'] = df_test['text_clean'].apply(lambda x: stopwords_count(x))\n",
    "df_test['caps_count'] = df_test['text_clean'].apply(lambda x: caps_count(x))\n",
    "df_test['repeated_words'] = df_test['text_clean'].apply(lambda x: repeated_words(x))\n",
    "\n",
    "df_test, _ = poly_features(df_test, poly=poly)\n",
    "\n",
    "df_test = df_test.join(encoder.transform(df_test[features]).add_suffix('_target'))\n",
    "\n",
    "urls_vec_test = vec_urls.transform(df_test['urls'])\n",
    "X_test_urls = pd.DataFrame(urls_vec_test.toarray(), columns=vec_urls.get_feature_names_out())\n",
    "handles_vec_test = vec_handles.transform(df_test['handles'])\n",
    "X_test_handles = pd.DataFrame(handles_vec_test.toarray(), columns=vec_handles.get_feature_names_out())\n",
    "hashtags_vec_test = vec_hashtags.transform(df_test['hashtags'])\n",
    "X_test_hashtags = pd.DataFrame(hashtags_vec_test.toarray(), columns=vec_hashtags.get_feature_names_out())\n",
    "text_vec_test = vec_text.transform(df_test['text_clean'])\n",
    "X_test_text = pd.DataFrame(text_vec_test.toarray(), columns=vec_text.get_feature_names_out())\n",
    "\n",
    "df_test = df_test.join(X_test_urls, rsuffix='_urls')\n",
    "df_test = df_test.join(X_test_handles, rsuffix='_handles')\n",
    "df_test = df_test.join(X_test_hashtags, rsuffix='_hashtags')\n",
    "df_test = df_test.join(X_test_text, rsuffix='_text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_to_drop = df_train.select_dtypes(exclude=['number']).columns.to_list()\n",
    "features_to_drop.extend(['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=features_to_drop+['target'])\n",
    "X_test = df_test.drop(columns=features_to_drop)\n",
    "y_train = df_train['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training f-1 score:\t\t0.6844\n",
      "Cross-validated f-1 score:\t0.6743\n"
     ]
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_test = lr.predict(X_test)\n",
    "print(f'Training f-1 score:\\t\\t{round(f1_score(y_train, lr.predict(X_train)),4)}')\n",
    "print(f'Cross-validated f-1 score:\\t{round(cross_val_score(lr, X_train, y_train, cv=5, scoring='f1').mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE (pre-scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positives: 3271 (43.0%)\n",
      "Negatives: 4342 (57.0%)\n",
      "X number of rows: 7613\n",
      "\n",
      "Positives: 4342 (50.0%)\n",
      "Negatives: 4342 (50.0%)\n",
      "X number of rows: 8684\n"
     ]
    }
   ],
   "source": [
    "print(f'Positives: {df_train[df_train.target==1].shape[0]} ({round(df_train[df_train.target==1].shape[0]/df_train.shape[0]*100,1)}%)')\n",
    "print(f'Negatives: {df_train[df_train.target==0].shape[0]} ({round(df_train[df_train.target==0].shape[0]/df_train.shape[0]*100,1)}%)')\n",
    "print(f'X number of rows: {X_train.shape[0]}')\n",
    "print()\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "print(f'Positives: {int(y_train[y_train==1].count())} ({round(int(y_train[y_train==1].count())/int(y_train.count())*100,1)}%)')\n",
    "print(f'Negatives: {int(y_train[y_train==0].count())} ({round(int(y_train[y_train==0].count())/int(y_train.count())*100,1)}%)')\n",
    "print(f'X number of rows: {y_train.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training f-1 score:\t\t0.7427\n",
      "Cross-validated f-1 score:\t0.732\n"
     ]
    }
   ],
   "source": [
    "# lr.fit(X_train, y_train)\n",
    "# y_test = lr.predict(X_test)\n",
    "# print(f'Training f-1 score:\\t\\t{round(f1_score(y_train, lr.predict(X_train)),4)}')\n",
    "# print(f'Cross-validated f-1 score:\\t{round(cross_val_score(lr, X_train, y_train, cv=5, scoring='f1').mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.fit(X_train_scaled, y_train)\n",
    "# y_test = lr.predict(X_test_scaled)\n",
    "# print(f'Training f-1 score:\\t\\t{round(f1_score(y_train, lr.predict(X_train_scaled)),4)}')\n",
    "# print(f'Cross-validated f-1 score:\\t{round(cross_val_score(lr, X_train_scaled, y_train, cv=5, scoring='f1').mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_spaces = [{'solver':['liblinear'], 'penalty':['l1','l2'], 'C':(1e-4, 1e4, 'log-uniform')}]\n",
    "# bayessearch_lr = BayesSearchCV(LogisticRegression(random_state=42), search_spaces=search_spaces, n_iter=100, scoring='f1', cv=5, n_jobs=-1)\n",
    "# bayessearch_lr.fit(X_train_scaled, y_train)\n",
    "# print(\"Best score:\", bayessearch_lr.best_score_)\n",
    "# print(\"Best parameters:\", bayessearch_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# param_grid = [{'solver':['liblinear'], 'penalty':['l1','l2'], 'C':[0.001, 0.01, 0.1, 1, 10, 100, 1000]}]\n",
    "# gridsearch_lr = GridSearchCV(LogisticRegression(random_state=42, max_iter=100), param_grid=param_grid, scoring='f1', cv=5, n_jobs=-1)\n",
    "# gridsearch_lr.fit(X_train_scaled, y_train)\n",
    "# print(\"Best score:\", gridsearch_lr.best_score_)\n",
    "# print(\"Best parameters:\", gridsearch_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr = bayessearch_lr.best_estimator_\n",
    "lr = LogisticRegression(random_state=42, C=0.14421478790765738, penalty='l1', solver='liblinear')\n",
    "# lr = gridsearch_lr.best_estimator_\n",
    "# lr = LogisticRegression(random_state=42, C=0.1, penalty='l1', solver='liblinear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.fit(X_train_scaled, y_train)\n",
    "# y_test = lr.predict(X_test_scaled)\n",
    "# print(f'Training f-1 score:\\t\\t{round(f1_score(y_train, lr.predict(X_train_scaled)),4)}')\n",
    "# print(f'Cross-validated f-1 score:\\t{round(cross_val_score(lr, X_train_scaled, y_train, cv=5, scoring='f1').mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: Select K Best, Variance Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selector_pipeline = Pipeline([('select',SelectKBest(score_func=chi2)), ('clf',lr)])\n",
    "# bayes_search_selector = BayesSearchCV(estimator=selector_pipeline, search_spaces={'select__k':(1,X_train_scaled.shape[1])}, n_iter=50, scoring='f1', cv=5, verbose=0, n_jobs=-1)\n",
    "# bayes_search_selector.fit(X_train_scaled, y_train)\n",
    "# print(\"Best k:\", bayes_search_selector.best_params_['select__k'])\n",
    "# print(\"Best F1 score:\", bayes_search_selector.best_score_)\n",
    "# selector = bayes_search_selector.best_estimator_[0]\n",
    "selector = SelectKBest(score_func=chi2, k=500)\n",
    "X_train_scaled = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_scaled = selector.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_selection import VarianceThreshold\n",
    "# selector = VarianceThreshold(threshold=0.01)\n",
    "# X_train = selector.fit_transform(X_train, y_train)\n",
    "# X_test = selector.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.fit(X_train_scaled, y_train)\n",
    "# y_test = lr.predict(X_test_scaled)\n",
    "# print(f'Training f-1 score:\\t\\t{round(f1_score(y_train, lr.predict(X_train_scaled)),4)}')\n",
    "# print(f'Cross-validated f-1 score:\\t{round(cross_val_score(lr, X_train_scaled, y_train, cv=5, scoring='f1').mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection: RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal number of features: 500\n"
     ]
    }
   ],
   "source": [
    "rfecv = RFECV(estimator=lr, step=1000, cv=2, scoring='f1')\n",
    "rfecv.fit(X_train_scaled, y_train)\n",
    "\n",
    "# plt.figure(figsize=(12,6))\n",
    "# plt.xlabel(\"Number of features selected\")\n",
    "# plt.ylabel(\"Number of correct classifications)\")\n",
    "# plt.plot(rfecv.cv_results_['n_features'], rfecv.cv_results_['mean_test_score'])\n",
    "# plt.show()\n",
    "\n",
    "print(\"Optimal number of features:\", rfecv.n_features_)\n",
    "# rfecv_features = rfecv.support_\n",
    "# print(\"Selected features:\", rfecv_features)\n",
    "# print(\"Selected features:\", X_train.columns[rfecv_features])\n",
    "# # print(\"Feature rankings:\", rfecv.ranking_)\n",
    "\n",
    "X_train_scaled = rfecv.transform(X_train_scaled)\n",
    "X_test_scaled = rfecv.transform(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.fit(X_train_scaled, y_train)\n",
    "# y_test = lr.predict(X_test_scaled)\n",
    "# print(f'Training f-1 score:\\t\\t{round(f1_score(y_train, lr.predict(X_train_scaled)),4)}')\n",
    "# print(f'Cross-validated f-1 score:\\t{round(cross_val_score(lr, X_train_scaled, y_train, cv=5, scoring='f1').mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative: SMOTE (post-scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(f'Positives: {df_train[df_train.target==1].shape[0]} ({round(df_train[df_train.target==1].shape[0]/df_train.shape[0]*100,1)}%)')\n",
    "# print(f'Negatives: {df_train[df_train.target==0].shape[0]} ({round(df_train[df_train.target==0].shape[0]/df_train.shape[0]*100,1)}%)')\n",
    "# print(f'X number of rows: {X_train.shape[0]}')\n",
    "# print()\n",
    "\n",
    "# smote = SMOTE(random_state=42)\n",
    "# X_train_scaled, y_train = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# print(f'Positives: {int(y_train[y_train==1].count())} ({round(int(y_train[y_train==1].count())/int(y_train.count())*100,1)}%)')\n",
    "# print(f'Negatives: {int(y_train[y_train==0].count())} ({round(int(y_train[y_train==0].count())/int(y_train.count())*100,1)}%)')\n",
    "# print(f'X number of rows: {y_train.shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr.fit(X_train_scaled, y_train)\n",
    "# y_test = lr.predict(X_test_scaled)\n",
    "# print(f'Training f-1 score:\\t\\t{round(f1_score(y_train, lr.predict(X_train_scaled)),4)}')\n",
    "# print(f'Cross-validated f-1 score:\\t{round(cross_val_score(lr, X_train_scaled, y_train, cv=5, scoring='f1').mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Fit and Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train_scaled, y_train)\n",
    "y_test = lr.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training f-1 score:\t0.864\n",
      "Training accuracy:\t0.8641\n"
     ]
    }
   ],
   "source": [
    "print(f'Training f-1 score:\\t{round(f1_score(y_train, lr.predict(X_train_scaled)),4)}')\n",
    "print(f'Training accuracy:\\t{round(lr.score(X_train_scaled, y_train),4)}')\n",
    "# cm = confusion_matrix(y_train, lr.predict(X_train_scaled))\n",
    "# display(pd.DataFrame(cm,index=['Actual Negative', 'Actual Positive'],columns=['Predicted Negative', 'Predicted Positive']))\n",
    "# display(pd.DataFrame((cm/cm.sum()*100).round(1),index=['Actual Negative (%)', 'Actual Positive (%)'],columns=['Predicted Negative (%)', 'Predicted Positive (%)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validated f-1 score:\t0.8613\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.model_selection import StratifiedKFold\n",
    "# cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "print(f'Cross-validated f-1 score:\\t{round(cross_val_score(lr, X_train_scaled, y_train, cv=5, scoring='f1').mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 0.8616 : smote scale lr (0.14421478790765738) rfecv (6!)\n",
    "- 0.8608: smote scale lr (0.14421478790765738) skb (2544)\n",
    "- 0.8607: smote scale lr (0.14421478790765738) skb (2464) rfecv (1014)\n",
    "- 0.8598: scale lr (0.3059596085116492) skb (2310) rfecv (460) smote\n",
    "- 0.8306 : defaults"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipeline = Pipeline([\n",
    "#     ('smote', SMOTE(random_state=42)),\n",
    "#     ('scaler', MinMaxScaler()),\n",
    "#     ('feature_selection', SelectKBest(score_func=chi2)),\n",
    "#     ('clf', LogisticRegression(random_state=42))\n",
    "# ])\n",
    "\n",
    "# param_grid = {\n",
    "#     'feature_selection__k': (1, X_train.shape[1]),\n",
    "#     'clf__solver': ['liblinear'],\n",
    "#     'clf__penalty': ['l1', 'l2'],\n",
    "#     'clf__C': (1e-4, 1e4, 'log-uniform')\n",
    "# }\n",
    "\n",
    "# bayes_search = BayesSearchCV(\n",
    "#     estimator=pipeline,\n",
    "#     search_spaces=param_grid,\n",
    "#     n_iter=100,\n",
    "#     scoring='f1',\n",
    "#     cv=10,\n",
    "#     n_jobs=-1,\n",
    "#     verbose=0\n",
    "# )\n",
    "\n",
    "# bayes_search.fit(X_train, y_train)\n",
    "# best_pipeline = bayes_search.best_estimator_\n",
    "\n",
    "# rfecv = RFECV(estimator=best_pipeline.named_steps['clf'], step=5, cv=10, scoring='f1')\n",
    "# X_train_rfecv = rfecv.fit_transform(best_pipeline[:-1].fit_transform(X_train, y_train), y_train)\n",
    "# X_test_rfecv = rfecv.transform(best_pipeline[:-1].transform(X_test))\n",
    "\n",
    "# best_pipeline.named_steps['clf'].fit(X_train_rfecv, y_train)\n",
    "# y_test = best_pipeline.named_steps['clf'].predict(X_test_rfecv)\n",
    "# print(f'Training f-1 score:\\t\\t{round(f1_score(y_train, lr.predict(X_train_scaled)),4)}')\n",
    "# print(f'Cross-validated f-1 score:\\t{round(cross_val_score(lr, X_train_scaled, y_train, cv=10, scoring='f1').mean(),4)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission['target'] = y_test\n",
    "# print(submission.shape)\n",
    "# submission.to_csv('submission_jg_8613.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
