{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 530
    },
    "colab_type": "code",
    "id": "Rlp5wUW_FDmH",
    "outputId": "375cb352-57f9-4bc4-aa5b-8a9824e8cad2"
   },
   "outputs": [],
   "source": [
    "# Importing the relevant packages\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading and preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before continuing with our model and training, our first job is to preprocess the dataset\n",
    "# This is a very important step in all of machine learning\n",
    "\n",
    "# The MNIST dataset is, in general, highly processed already - after all its 28x28 grayscale images of clearly visible digits\n",
    "# Thus, our preprocessing will be limited to scaling the pixel values, shuffling the data and creating a validation set\n",
    "\n",
    "# NOTE: When finally deploying a model in practice, it might be a good idea to include the prerpocessing as initial layers\n",
    "# In that way, the users could just plug the data (images) directly, instead of being required to resize/rescale it before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining some constants/hyperparameters\n",
    "BUFFER_SIZE = 70_000 # for reshuffling\n",
    "BATCH_SIZE = 128\n",
    "NUM_EPOCHS = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': <_PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>,\n",
       " 'test': <_PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tfds.core.DatasetInfo(\n",
       "    name='mnist',\n",
       "    full_name='mnist/3.0.1',\n",
       "    description=\"\"\"\n",
       "    The MNIST database of handwritten digits.\n",
       "    \"\"\",\n",
       "    homepage='http://yann.lecun.com/exdb/mnist/',\n",
       "    data_dir='/Users/jgibb/tensorflow_datasets/mnist/3.0.1',\n",
       "    file_format=tfrecord,\n",
       "    download_size=11.06 MiB,\n",
       "    dataset_size=21.00 MiB,\n",
       "    features=FeaturesDict({\n",
       "        'image': Image(shape=(28, 28, 1), dtype=uint8),\n",
       "        'label': ClassLabel(shape=(), dtype=int64, num_classes=10),\n",
       "    }),\n",
       "    supervised_keys=('image', 'label'),\n",
       "    disable_shuffling=False,\n",
       "    nondeterministic_order=False,\n",
       "    splits={\n",
       "        'test': <SplitInfo num_examples=10000, num_shards=1>,\n",
       "        'train': <SplitInfo num_examples=60000, num_shards=1>,\n",
       "    },\n",
       "    citation=\"\"\"@article{lecun2010mnist,\n",
       "      title={MNIST handwritten digit database},\n",
       "      author={LeCun, Yann and Cortes, Corinna and Burges, CJ},\n",
       "      journal={ATT Labs [Online]. Available: http://yann.lecun.com/exdb/mnist},\n",
       "      volume={2},\n",
       "      year={2010}\n",
       "    }\"\"\",\n",
       ")"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downloading the MNIST dataset\n",
    "\n",
    "# When 'with_info' is set to True, tfds.load() returns two variables: \n",
    "# - the dataset (including the train and test sets) \n",
    "# - meta info regarding the dataset itself\n",
    "\n",
    "mnist_dataset, mnist_info = tfds.load(name='mnist', with_info=True, as_supervised=True)\n",
    "\n",
    "display(mnist_dataset)\n",
    "display(mnist_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_PrefetchDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.uint8, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extracting the train and test datasets\n",
    "mnist_train, mnist_test = mnist_dataset['train'], mnist_dataset['test']\n",
    "\n",
    "mnist_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Creating a function to scale our image data (it is recommended to scale the pixel values in the range [0,1] )\n",
    "def scale(image, label):\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    image /= 255.\n",
    "\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_MapDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scaling the data\n",
    "train_and_validation_data = mnist_train.map(scale)\n",
    "test_data = mnist_test.map(scale)\n",
    "\n",
    "train_and_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=6000>"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the size of the validation set\n",
    "num_validation_samples = 0.1 * mnist_info.splits['train'].num_examples\n",
    "num_validation_samples = tf.cast(num_validation_samples, tf.int64)\n",
    "\n",
    "num_validation_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=int64, numpy=10000>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the size of the test set\n",
    "num_test_samples = mnist_info.splits['test'].num_examples\n",
    "num_test_samples = tf.cast(num_test_samples, tf.int64)\n",
    "\n",
    "num_test_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_ShuffleDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshuffling the dataset\n",
    "train_and_validation_data = train_and_validation_data.shuffle(BUFFER_SIZE)\n",
    "\n",
    "train_and_validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_SkipDataset element_spec=(TensorSpec(shape=(28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into training + validation\n",
    "train_data = train_and_validation_data.skip(num_validation_samples)\n",
    "validation_data = train_and_validation_data.take(num_validation_samples)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 28, 28, 1), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int64, name=None))>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Batching the data\n",
    "# NOTE: For proper functioning of the model, we need to create one big batch for the validation and test sets\n",
    "train_data = train_data.batch(BATCH_SIZE)\n",
    "validation_data = validation_data.batch(num_validation_samples) \n",
    "test_data = test_data.batch(num_test_samples)\n",
    "\n",
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the model and training it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we have preprocessed the dataset, we can define our CNN and train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Outlining the model/architecture of our CNN\n",
    "# CONV -> MAXPOOL -> CONV -> MAXPOOL -> FLATTEN -> DENSE\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(28, 28, 1)),\n",
    "    tf.keras.layers.Conv2D(50, 5, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    # (2,2) is the default pool size so we could have just used MaxPooling2D() with no explicit arguments\n",
    "    tf.keras.layers.Conv2D(50, 3, activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2,2)), \n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(10) # You can apply softmax activation here, see below for comentary\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                   </span>┃<span style=\"font-weight: bold\"> Output Shape            </span>┃<span style=\"font-weight: bold\">      Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,300</span> │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ max_pooling2d_10               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)      │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │                         │              │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ conv2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">22,550</span> │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ max_pooling2d_11               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)        │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)                 │                         │              │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ flatten_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1250</span>)            │            <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)              │       <span style=\"color: #00af00; text-decoration-color: #00af00\">12,510</span> │\n",
       "└────────────────────────────────┴─────────────────────────┴──────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape           \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m     Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━┩\n",
       "│ conv2d_10 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m50\u001b[0m)      │        \u001b[38;5;34m1,300\u001b[0m │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ max_pooling2d_10               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m50\u001b[0m)      │            \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │                         │              │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ conv2d_11 (\u001b[38;5;33mConv2D\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m50\u001b[0m)      │       \u001b[38;5;34m22,550\u001b[0m │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ max_pooling2d_11               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m50\u001b[0m)        │            \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mMaxPooling2D\u001b[0m)                 │                         │              │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ flatten_5 (\u001b[38;5;33mFlatten\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1250\u001b[0m)            │            \u001b[38;5;34m0\u001b[0m │\n",
       "├────────────────────────────────┼─────────────────────────┼──────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)              │       \u001b[38;5;34m12,510\u001b[0m │\n",
       "└────────────────────────────────┴─────────────────────────┴──────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,360</span> (142.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m36,360\u001b[0m (142.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">36,360</span> (142.03 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m36,360\u001b[0m (142.03 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A brief summary of the model and parameters\n",
    "model.summary(line_length = 75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the loss function\n",
    "\n",
    "# In general, our model needs to output probabilities of each class, \n",
    "# which can be achieved with a softmax activation in the last dense layer\n",
    "\n",
    "# However, when using the softmax activation, the loss can rarely be unstable\n",
    "\n",
    "# Thus, instead of incorporating the softmax into the model itself,\n",
    "# we use a loss calculation that automatically corrects for the missing softmax\n",
    "\n",
    "# That is the reason for 'from_logits=True'\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Compiling the model with Adam optimizer and the categorical crossentropy as a loss function\n",
    "model.compile(optimizer='adam', loss=loss_fn, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "9S6uGLzkFDmP",
    "outputId": "6a5bad6b-035f-4f2e-a81c-8015e17001f4"
   },
   "outputs": [],
   "source": [
    "# Defining early stopping to prevent overfitting\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor = 'val_loss',\n",
    "    mode = 'auto',    \n",
    "    min_delta = 0,\n",
    "    patience = 2,\n",
    "    verbose = 0, \n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logging the training process data to use later in tensorboard\n",
    "log_dir = \"./logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-13 17:26:27.978086: I tensorflow/core/kernels/data/tf_record_dataset_op.cc:387] The default buffer size is 262144, which is overridden by the user specified `buffer_size` of 8388608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 16ms/step - accuracy: 0.8276 - loss: 0.6133 - val_accuracy: 0.9747 - val_loss: 0.0898\n",
      "Epoch 2/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9770 - loss: 0.0758 - val_accuracy: 0.9867 - val_loss: 0.0477\n",
      "Epoch 3/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.9841 - loss: 0.0515 - val_accuracy: 0.9892 - val_loss: 0.0374\n",
      "Epoch 4/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 17ms/step - accuracy: 0.9877 - loss: 0.0402 - val_accuracy: 0.9893 - val_loss: 0.0343\n",
      "Epoch 5/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9889 - loss: 0.0377 - val_accuracy: 0.9917 - val_loss: 0.0280\n",
      "Epoch 6/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9906 - loss: 0.0302 - val_accuracy: 0.9933 - val_loss: 0.0214\n",
      "Epoch 7/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9923 - loss: 0.0262 - val_accuracy: 0.9925 - val_loss: 0.0223\n",
      "Epoch 8/20\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 16ms/step - accuracy: 0.9933 - loss: 0.0232 - val_accuracy: 0.9935 - val_loss: 0.0223\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x15fa144d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the network\n",
    "model.fit(\n",
    "    train_data, \n",
    "    epochs = NUM_EPOCHS, \n",
    "    callbacks = [tensorboard_callback, early_stopping], \n",
    "    validation_data = validation_data,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.9913 - loss: 0.0276\n"
     ]
    }
   ],
   "source": [
    "# Testing our model\n",
    "test_loss, test_accuracy = model.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nFoXl2txFDmV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0276. Test accuracy: 99.13%\n"
     ]
    }
   ],
   "source": [
    "# Printing the test results\n",
    "print('Test loss: {0:.4f}. Test accuracy: {1:.2f}%'.format(test_loss, test_accuracy*100.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting images and the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the test_data into 2 arrays, containing the images and the corresponding labels\n",
    "for images, labels in test_data.take(1):\n",
    "    images_test = images.numpy()\n",
    "    labels_test = labels.numpy()\n",
    "\n",
    "# Reshape the images into 28x28 form, suitable for matplotlib (original dimensions: 28x28x1)\n",
    "images_plot = np.reshape(images_test, (10000,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAK8AAACuCAYAAABAzl3QAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAABO1JREFUeJzt3c8rtGscx/GZMxTKj6wssLKSlCRFpLCQ7ETxD/hRk39BsZKVJHsbDRvJQomSmIWUFVaysEB+lBKGedI5u+s7zuU443k+17xfy2+X263e3T3Xfc/9TDSdTqcjgKC/fvcJAP8V8UIW8UIW8UIW8UIW8UIW8UIW8UIW8UJWnu/CaDSa3TMB/uH70JcrL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL2QRL8L/7mGEpbCw0Jx3dnZ6H+Pp6cmZbW1tRX4KV17IIl7IIl7IIl7IyrkNWywWc2ZTU1Pm2sHBQe/jWhuVTMe9uLgw5+l0+lt/R8yYfZicnHRmQ0ND5trKykrvc0ilUs5sf3/fXDswMODMrq6uIt/BlReyiBeyiBeyiBeyiBeyomnPLW40Go0oKS4uNueJRMKZdXd3R35SPB435ycnJ86sv7/fXNvU1OTMGhoaIkoy3R3xvevClReyiBeyiBeyiBeygtiwVVVVObP19XVzbV1dnfdxLy8vndno6Ki5trm52ZmNjIyYa8vLyyN/qmQy6cxmZ2fNtbe3t9/6Xdvb2+acDRuCR7yQRbyQRbyQRbyQFcTdhs3NzW+9BWvdVfjQ29vrzI6Pj72Pu7u7a85bWloi2fD8/GzOl5aWnNn09LS51vqAuPWWcDZxtwHBI17IIl7IIl7ICuLt4a6uLu9/9L+9vXn9/IfT09PI73Z3d2fOl5eXndnMzIy59vz8PBIirryQRbyQRbyQRbyQRbyQFcTjYetPeH9/N9e+vr46s4KCgqycV319vTmfmJgw5w8PD85sYWHBXHt2dhYJFY+HETzihSzihSzihawgNmxzc3PObGxszPvnx8fHvT8H+/j4+MWzw1exYUPwiBeyiBeyiBeyiBeygrjbUFJS4sxWVlbMtV95q3hnZ8eZ9fT0mGtfXl68j4vPcbcBwSNeyCJeyCJeyApiw2YpKysz56urq86so6PD+7gHBwfmvLW19Qtnh8+wYUPwiBeyiBeyiBeyiBeygr3bkElRUZEz29jYMNe2tbV5H3dxcdH7LWEeJX+Ouw0IHvFCFvFCFvFCVs5t2CylpaXmPJFIfOvzwO3t7eZ8b2/vC2eXe9Js2BA64oUs4oUs4oUs4oUs7jZ8orGx0euN4kyPnefn58218Xj8fzi7cHG3AcEjXsgiXsgiXsgK4ruHs+Xw8NCZ3d/fe2/YqqurzbWxWMz7e5GRGVdeyCJeyCJeyCJeyCJeyMq5uw15eXne3++bTCadWXl5uffv6uvrM+eZjnF9fe19bHDlhTDihSzihSzihayc+zyvtWE7Ojoy19bW1mblHCoqKsw5G7a/8XleBI94IYt4IYt4IYt4ISvnHg+nUinv/39seHjYmeXn55tra2pqnNna2pq59ubmxuNM8W+48kIW8UIW8UIW8UJWzj0exp+Px8MIHvFCFvFCFvFCFvFCFvFCFvFCFvFCFvFCFvFCFvFCFvFCFvFCFvFCFvFCFvEi/LeHfT8gDPwUrryQRbyQRbyQRbyQRbyQRbyQRbyQRbyQRbyIqPoF6XIjasWGQvQAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: 5\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The image to be displayed and tested\n",
    "i = 502\n",
    "\n",
    "# Plot the image\n",
    "plt.figure(figsize=(2, 2))\n",
    "plt.axis('off')\n",
    "plt.imshow(images_plot[i-1], cmap=\"gray\", aspect='auto')\n",
    "plt.show()\n",
    "\n",
    "# Print the correct label for the image\n",
    "print(\"Label: {}\".format(labels_test[i-1]))\n",
    "\n",
    "# Obtain the model's predictions (logits)\n",
    "predictions = model.predict(images_test[i-1:i])\n",
    "\n",
    "# Convert those predictions into probabilities (recall that we incorporated the softmaxt activation into the loss function)\n",
    "probabilities = tf.nn.softmax(predictions).numpy()\n",
    "# Convert the probabilities into percentages\n",
    "probabilities = probabilities*100\n",
    "\n",
    "\n",
    "# Create a bar chart to plot the probabilities for each class\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.bar(x=[1,2,3,4,5,6,7,8,9,10], height=probabilities[0], tick_label=[\"0\",\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing in Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-740b2234013634e8\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-740b2234013634e8\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 8088;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading the Tensorboard extension\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"logs/fit\" --host localhost --port 8088"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "defaultNotebook.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
