{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39f42f96",
   "metadata": {},
   "source": [
    "## Nulls summary table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "325bde1f-f4c8-49a7-a98f-6e1cefaeaa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nulls_summary_table(df):\n",
    "    \"\"\"\n",
    "    Returns a summary table showing null value counts and percentage\n",
    "    \n",
    "    Parameters:\n",
    "    df (DataFrame): Dataframe to check\n",
    "    \n",
    "    Returns:\n",
    "    null_values (DataFrame)\n",
    "    \"\"\"\n",
    "    null_values = pd.DataFrame(df.isnull().sum())\n",
    "    null_values[1] = null_values[0]/len(df)\n",
    "    null_values.columns = ['null_count','null_pct']\n",
    "    return null_values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c402e43c",
   "metadata": {},
   "source": [
    "## Time benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1028d6c-e5b9-44f7-a6b1-796eca37e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate sample data\n",
    "np.random.seed(0)\n",
    "data = np.random.rand(10000, 2)\n",
    "df = pd.DataFrame(data, columns=['A', 'B'])\n",
    "a, b = data[:, 0], data[:, 1]\n",
    "\n",
    "# Benchmark pandas\n",
    "pandas_time = timeit.timeit(lambda: df['A'].corr(df['B'], method='pearson'), number=1000)\n",
    "print(f\"Pandas: {pandas_time} seconds\")\n",
    "\n",
    "# Benchmark numpy\n",
    "numpy_time = timeit.timeit(lambda: np.corrcoef(a, b)[0, 1], number=1000)\n",
    "print(f\"Numpy: {numpy_time} seconds\")\n",
    "\n",
    "# Benchmark scipy\n",
    "scipy_time = timeit.timeit(lambda: pearsonr(a, b)[0], number=1000)\n",
    "print(f\"Scipy: {scipy_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0467f490",
   "metadata": {},
   "source": [
    "## K-means mathematical elbow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e7ebbfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Largest percentage change:\t\t64.83%\tbetween points 4 and 5\n",
      "Largest relative percentage change:\t100.00%\tbetween points 6 and 7\n"
     ]
    }
   ],
   "source": [
    "# wcss = []\n",
    "# for i in range(1,11):\n",
    "#     kmeans = KMeans(n_clusters = i, init = 'k-means++', random_state = 42)\n",
    "#     kmeans.fit(data)\n",
    "#     wcss.append(kmeans.inertia_)\n",
    "# wcss_data = dict(zip(range(1, 11), wcss))\n",
    "\n",
    "wcss_data = {1: 14000.000000000002,\n",
    " 2: 10674.294049383006,\n",
    " 3: 8907.898028914926,\n",
    " 4: 7761.474180989327,\n",
    " 5: 6449.492103746886,\n",
    " 6: 5988.100866179874,\n",
    " 7: 5705.051575716015,\n",
    " 8: 5066.316782614302,\n",
    " 9: 4754.754386186658,\n",
    " 10: 4465.7488481144765}\n",
    "\n",
    "gradients = []\n",
    "keys = list(wcss_data.keys())\n",
    "\n",
    "for i in range(1, len(keys)):\n",
    "    gradient = wcss_data[keys[i]] - wcss_data[keys[i - 1]]\n",
    "    gradients.append(gradient)\n",
    "\n",
    "percentage_changes = []\n",
    "for i in range(1, len(gradients)):\n",
    "    change = (gradients[i] - gradients[i - 1]) / abs(gradients[i - 1]) * 100\n",
    "    percentage_changes.append(change)\n",
    "\n",
    "max_change = max(percentage_changes)\n",
    "max_index = percentage_changes.index(max_change) + 2  # Adding 2 because index starts at 1 and we skip the first gradient\n",
    "\n",
    "print(f\"Largest percentage change:\\t\\t{max_change:.2f}%\\tbetween points {max_index-1} and {max_index}\")\n",
    "\n",
    "max_gradient = max(gradients)\n",
    "min_gradient = min(gradients)\n",
    "\n",
    "relative_percentage_changes = []\n",
    "for gradient in gradients:\n",
    "    change = (gradient - min_gradient) / (max_gradient - min_gradient) * 100\n",
    "    relative_percentage_changes.append(change)\n",
    "\n",
    "max_change = max(relative_percentage_changes)\n",
    "max_index = relative_percentage_changes.index(max_change) + 2  # Adding 2 because index starts at 1 and we skip the first gradient\n",
    "\n",
    "print(f\"Largest relative percentage change:\\t{max_change:.2f}%\\tbetween points {max_index-1} and {max_index}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
